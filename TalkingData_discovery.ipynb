{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icervera/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data...\n",
      "[107.9268307685852] Finished to load data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(184903890, 8)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_tree\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "path = '/home/icervera/workspace-python/kaggle/AdTracking/data/'\n",
    "\n",
    "dtypes = {'ip'            : 'uint32',\n",
    "          'app'           : 'uint16',\n",
    "          'device'        : 'uint16',\n",
    "          'os'            : 'uint16',\n",
    "          'channel'       : 'uint16',\n",
    "          'is_attributed' : 'uint8',\n",
    "          'click_id'      : 'uint32'\n",
    "          }\n",
    "\n",
    "print('loading train data...')\n",
    "start_time = time.time()\n",
    "#train_df = pd.read_csv(path+\"train.csv\", nrows=10000000, dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'attributed_time','is_attributed'])\n",
    "train_df = pd.read_csv(path+\"train.csv\", dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'attributed_time','is_attributed'])\n",
    "\n",
    "# total observations: 184,903,891\n",
    "\n",
    "print('[{}] Finished to load data'.format(time.time() - start_time))\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting day and hour...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_attributed</th>\n",
       "      <th>hour_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:32:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14.539167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:33:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14.559444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:34:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14.570000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>2017-11-06 14:34:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14.581111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:35:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14.585556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel           click_time attributed_time  \\\n",
       "0   83230    3       1  13      379  2017-11-06 14:32:21             NaN   \n",
       "1   17357    3       1  19      379  2017-11-06 14:33:34             NaN   \n",
       "2   35810    3       1  13      379  2017-11-06 14:34:12             NaN   \n",
       "3   45745   14       1  13      478  2017-11-06 14:34:52             NaN   \n",
       "4  161007    3       1  13      379  2017-11-06 14:35:08             NaN   \n",
       "\n",
       "   is_attributed  day       hour  day_attributed  hour_attributed  \n",
       "0              0    6  14.539167             NaN              NaN  \n",
       "1              0    6  14.559444             NaN              NaN  \n",
       "2              0    6  14.570000             NaN              NaN  \n",
       "3              0    6  14.581111             NaN              NaN  \n",
       "4              0    6  14.585556             NaN              NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Extracting day and hour...')\n",
    "#train_df['hour'] = pd.to_datetime(train_df.click_time).dt.hour.astype('uint8')\n",
    "train_df['day']  = pd.to_datetime(train_df.click_time).dt.day.astype('uint8')\n",
    "\n",
    "train_df['hour'] = pd.to_datetime(train_df.click_time).dt.second/3600 + pd.to_datetime(train_df.click_time).dt.minute/60 + pd.to_datetime(train_df.click_time).dt.hour\n",
    "\n",
    "\n",
    "train_df['day_attributed']  = pd.to_datetime(train_df.attributed_time, errors='coerce').dt.day\n",
    "\n",
    "train_df['hour_attributed'] = pd.to_datetime(train_df.attributed_time, errors='coerce').dt.second/3600 + pd.to_datetime(train_df.attributed_time, errors='coerce').dt.minute/60 + pd.to_datetime(train_df.attributed_time, errors='coerce').dt.hour\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.drop(columns=['click_time'])\n",
    "train_df.head()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_attributed</th>\n",
       "      <th>hour_attributed</th>\n",
       "      <th>click_byIp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14.539167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14.559444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14.570000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14.581111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14.585556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel attributed_time  is_attributed  day  \\\n",
       "0   83230    3       1  13      379             NaN              0    6   \n",
       "1   17357    3       1  19      379             NaN              0    6   \n",
       "2   35810    3       1  13      379             NaN              0    6   \n",
       "3   45745   14       1  13      478             NaN              0    6   \n",
       "4  161007    3       1  13      379             NaN              0    6   \n",
       "\n",
       "        hour  day_attributed  hour_attributed  click_byIp  \n",
       "0  14.539167             NaN              NaN       25719  \n",
       "1  14.559444             NaN              NaN       24133  \n",
       "2  14.570000             NaN              NaN        9791  \n",
       "3  14.581111             NaN              NaN       38077  \n",
       "4  14.585556             NaN              NaN        1171  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of clicks by ip\n",
    "ip_count = train_df.groupby('ip')['channel'].count().reset_index()\n",
    "ip_count.columns = ['ip',  'click_byIp']\n",
    "train_df = pd.merge(train_df, ip_count, on='ip', how='left', sort=False)\n",
    "train_df['click_byIp'] = train_df['click_byIp'].astype('uint16')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df = train_df.sort_values(by=['ip','day','hour'], ascending=[True,True,True])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calcul the time between this click and the last click: click_interval_before\n",
    "# calcul the time between this click and the next click: click_interval_after\n",
    "# need to sort the df by ip, day, hour before doing this\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_df['hour-1'] = train_df['hour'].shift(1)\n",
    "train_df['ip-1'] = train_df['ip'].shift(1)\n",
    "train_df['day-1'] = train_df['day'].shift(1)\n",
    "\n",
    "\n",
    "train_df['hour+1'] = train_df['hour'].shift(-1)\n",
    "train_df['ip+1'] = train_df['ip'].shift(-1)\n",
    "train_df['day+1'] = train_df['day'].shift(-1)\n",
    "\n",
    "click_interval_before = []\n",
    "click_interval_after = []\n",
    "for index, row in train_df.iterrows():\n",
    "    if (row['day']==row['day-1'] and row['ip']==row['ip-1']):\n",
    "        click_interval_before.append(row['hour'] - row['hour-1'])\n",
    "    else :\n",
    "        # click_interval_before.append(24)\n",
    "        click_interval_before.append(row['hour'])\n",
    "    if (row['day']==row['day+1'] and row['ip']==row['ip+1']):\n",
    "        click_interval_after.append(row['hour+1'] - row['hour'])\n",
    "    else :\n",
    "        # click_interval_after.append(24)\n",
    "        click_interval_after.append(24 - row['hour'])\n",
    "train_df['click_interval_before'] = click_interval_before\n",
    "train_df['click_interval_after'] = click_interval_after\n",
    "\n",
    "print('[{}] Finished to load data'.format(time.time() - start_time))\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del click_interval_before\n",
    "del click_interval_after\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['day-1', 'hour-1', 'ip-1' ], axis=1)\n",
    "train_df = train_df.drop(['day+1', 'hour+1', 'ip+1' ], axis=1)\n",
    "gc.collect()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# comportement global d'un IP via la distribution des clicks\n",
    "# calcul the 0.9 quantile of hour_byIP\n",
    "\n",
    "# Count the number of clicks by ip\n",
    "#ip_count = train_df.groupby('ip')['hour'].quantile(0.8).reset_index()\n",
    "#ip_count.columns = ['ip',  'hour_byIP_08quantile']\n",
    "#train_df = pd.merge(train_df, ip_count, on='ip', how='left', sort=False)\n",
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# comportement journalié d'un IP via la distribution des clicks sur la journée \n",
    "# calcul the 0.8 quantile of hour_byIP\n",
    "\n",
    "# Count the number of clicks by ip\n",
    "#ip_count = train_df.groupby(['ip','day'])['hour'].quantile(0.8).reset_index()\n",
    "#ip_count.columns = ['ip','day',  'hour_byIP_byDay_08quantile']\n",
    "#train_df = pd.merge(train_df, ip_count, on=['ip','day'], how='left', sort=False)\n",
    "#train_df.head()\n",
    "\n",
    "#train_df = train_df.drop(['click_interval_after_median_x', 'click_interval_after_median_y', \n",
    "#                          'click_interval_before_median_x', 'click_interval_before_median_y', ], axis=1)\n",
    "#train_df = train_df.drop(['click_interval_after_mad',\n",
    "#                          'click_interval_before_mad' ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calcul the median and mad of click_interval_after\n",
    "\n",
    "ip_count = train_df.groupby('ip')['click_interval_after'].median().reset_index()\n",
    "ip_count.columns = ['ip',  'click_interval_after_median']\n",
    "train_df = pd.merge(train_df, ip_count, on='ip', how='left', sort=False)\n",
    "#train_df['click_interval_after_median'] = train_df['click_interval_after_median'].astype('uint16')\n",
    "\n",
    "if (FALSE):\n",
    "    ip_count = train_df.groupby('ip')['click_interval_after'].mad().reset_index()\n",
    "    ip_count.columns = ['ip',  'click_interval_after_mad']\n",
    "    train_df = pd.merge(train_df, ip_count, on='ip', how='left', sort=False)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calcul the median and mad of click_interval_before\n",
    "\n",
    "ip_count = train_df.groupby('ip')['click_interval_before'].median().reset_index()\n",
    "ip_count.columns = ['ip',  'click_interval_before_median']\n",
    "train_df = pd.merge(train_df, ip_count, on='ip', how='left', sort=False)\n",
    "#train_df['click_interval_after_median'] = train_df['click_interval_after_median'].astype('uint16')\n",
    "\n",
    "if (FALSE):\n",
    "    ip_count = train_df.groupby('ip')['click_interval_before'].mad().reset_index()\n",
    "    ip_count.columns = ['ip',  'click_interval_before_mad']\n",
    "    train_df = pd.merge(train_df, ip_count, on='ip', how='left', sort=False)\n",
    "    \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#start_time = time.time()\n",
    "#click_interval_before_distance = []\n",
    "#click_interval_after_distance = []\n",
    "#for index, row in train_df.iterrows():\n",
    "#    if (row['click_interval_before']<row['click_interval_before_median']):\n",
    "#        click_interval_before_distance.append(row['click_interval_before_median']-\n",
    "#                                              row['click_interval_before_mad']-\n",
    "#                                              row['click_interval_before'])\n",
    "#    else :\n",
    "#        click_interval_before_distance.append(row['click_interval_before']-(\n",
    "#                                              row['click_interval_before_median']+\n",
    "#                                              row['click_interval_before_mad']))\n",
    "#        \n",
    "#    if (row['click_interval_after']<row['click_interval_after_median']):\n",
    "#        click_interval_after_distance.append(row['click_interval_after_median']-\n",
    "#                                              row['click_interval_after_mad']-\n",
    "#                                              row['click_interval_after'])\n",
    "#    else :\n",
    "#        click_interval_after_distance.append(row['click_interval_after']-(\n",
    "#                                              row['click_interval_after_median']+\n",
    "#                                              row['click_interval_after_mad']))\n",
    "#train_df['click_interval_before_distance'] = click_interval_before_distance\n",
    "#train_df['click_interval_after_distance'] = click_interval_after_distance#\n",
    "#print('[{}] Finished to load data'.format(time.time() - start_time))\n",
    "\n",
    "\n",
    "train_df['click_interval_before_distance'] =np.arcsinh( train_df['click_interval_before']-train_df['click_interval_before_median'])\n",
    "train_df['click_interval_after_distance'] = np.arcsinh( train_df['click_interval_after']-train_df['click_interval_after_median'] )\n",
    "\n",
    "train_df['click_interval_before_after_dist'] = train_df['click_interval_before']+train_df['click_interval_after']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['download_interval'] = (train_df['day_attributed']-train_df['day'])*24 +\\\n",
    "    train_df['hour_attributed']-train_df['hour']\n",
    "train_df.head()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ggplot import *\n",
    "\n",
    "if (FALSE) : \n",
    "    tpm_df = train_df.loc[train_df['is_attributed']==1]\n",
    "    tpm_df.assign(is_attributed = lambda x: pd.Series(np.repeat(1, x.shape[0]), index=x.index)) \n",
    "    tpm2_df = train_df.loc[train_df['is_attributed']!=1].sample(18000, axis=0)\n",
    "    tpm2_df.assign(is_attributed = lambda x: pd.Series(np.repeat(0, x.shape[0]), index=x.index)) \n",
    "    rdm_df = pd.concat([tpm_df,tpm2_df])\n",
    "\n",
    "    rdm_df = rdm_df.assign(is_attributed_char = lambda x: x.is_attributed.astype(str)) \n",
    "\n",
    "    ggplot(rdm_df, aes('click_interval_before', fill='is_attributed_char'))+\\\n",
    "    geom_histogram(binwidth=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if (FALSE) : \n",
    "    ska_df = rdm_df.loc[rdm_df['is_attributed']==1]\n",
    "    ska_df['click_interval_after_log'] = np.log(ska_df['click_interval_after']+1)\n",
    "    ska_df['download_interval_log'] = np.log(ska_df['download_interval']+1)\n",
    "    ska_df['click_byChannel_log'] = np.log(ska_df['click_byChannel']+1)\n",
    "    ska_df['click_byIp_log'] = np.log(ska_df['click_byIp']+1)\n",
    "    ggplot(ska_df, aes('click_byIp_log', 'download_interval'))+geom_point(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NbrClickOnThisAppBefore_byDay \n",
    "# ratioClickOnThisAppBefore_byDay = NbrClickOnThisAppBefore_byDay / NbrClickOnAppsBefore_byDay\n",
    "\n",
    "max_clicks_by_ip = train_df['click_byIp'].max()\n",
    "\n",
    "\n",
    "#sample_train_df = train_df.sample(100000, axis=0)\n",
    "#sample_train_df = sample_train_df.sort_values(by=['ip','day','hour'], ascending=[True,True,True])\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "NbrClickOnThisAppBefore_byDay = []\n",
    "NbrClickBefore_byDay = []\n",
    "NbrClickOnThisAppAfter_byDay = []\n",
    "#NbrClick_byDay = []\n",
    "for index, row in train_df.iterrows():\n",
    "    # create a tpm_df which have all the row with the same ip and same day before the index ip\n",
    "    if(index<(max_clicks_by_ip+1)):\n",
    "        index_min=0\n",
    "    else:\n",
    "        index_min=index-max_clicks_by_ip\n",
    "    if(index>0):\n",
    "        tpm_df = train_df.iloc[(index_min):(index)]\n",
    "        #tpm_df = train_df.iloc[0:(index)]\n",
    "        tpm_df = tpm_df.loc[(tpm_df['ip'] == row['ip']) & (tpm_df['day'] == row['day']) ]\n",
    "        clickOnThisAppBefore = np.sum(tpm_df['app']==row['app'])\n",
    "        click = tpm_df.shape[0]\n",
    "        #ip_count = tpm_df.groupby(['ip','day','app'])['device'].count().reset_index()\n",
    "        #ip_count.columns = ['ip',  'day','app','value']\n",
    "        #clickOnApp = ip_count.loc[(ip_count['ip'] == row['ip']) & (ip_count['day'] == row['day']) & (ip_count['app'] == row['app'])   ]['value'].iloc[0]\n",
    "        #click = ip_count.loc[(ip_count['ip'] == row['ip']) & (ip_count['day'] == row['day'])].shape[0]\n",
    "    else:\n",
    "        clickOnThisAppBefore=0\n",
    "        click=0\n",
    "        \n",
    "    tpm_dfAfter = train_df.iloc[(index+1):(index+index_min)]\n",
    "    #tpm_df = train_df.iloc[0:(index)]\n",
    "    tpm_dfAfter = tpm_dfAfter.loc[(tpm_dfAfter['ip'] == row['ip']) & (tpm_dfAfter['day'] == row['day']) ]\n",
    "    clickOnThisAppAfter = np.sum(tpm_dfAfter['app']==row['app'])\n",
    "        \n",
    "    #clickTotal = sample_train_df.loc[(sample_train_df['ip'] == row['ip']) & (sample_train_df['day'] == row['day']) ].shape[0]\n",
    "    NbrClickOnThisAppBefore_byDay.append(clickOnThisAppBefore)\n",
    "    NbrClickBefore_byDay.append(click)\n",
    "    NbrClickOnThisAppAfter_byDay.append(clickOnThisAppAfter)\n",
    "    #NbrClick_byDay.append(clickTotal)\n",
    "train_df['click_onAppBefore_byDayByIp'] = NbrClickOnThisAppBefore_byDay\n",
    "train_df['click_Before_byDayByIp'] = NbrClickBefore_byDay\n",
    "train_df['click_onAppAfter_byDayByIp'] = NbrClickOnThisAppAfter_byDay\n",
    "\n",
    "# le 'NbrClick_byDay' on peut le faire plus rapidement avec un groupBy sans la boucle for\n",
    "# sample_train_df['NbrClick_byDay'] = NbrClick_byDay \n",
    "\n",
    "print('[{}] Finished to load data'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del NbrClickOnThisAppBefore_byDay\n",
    "del NbrClickBefore_byDay\n",
    "del NbrClickOnThisAppAfter_byDay\n",
    "del tpm_df\n",
    "del tpm_dfAfter\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count the number of clicks by day by ip\n",
    "ip_count = train_df.groupby(['ip','day'])['channel'].count().reset_index()\n",
    "ip_count.columns = ['ip','day',  'click_byDayByIp']\n",
    "train_df = pd.merge(train_df, ip_count, on=['ip','day'], how='left', sort=False)\n",
    "train_df['click_byDayByIp'] = train_df['click_byDayByIp'].astype('uint16')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# est ce que cela peut etre bien de faire de la regression sur le temps que lutilisateur met pr telecharger? \n",
    "# au lieu de faire de la classification?\n",
    "train_df['ratio_click_onAppBefore_byDayByIp'] = (train_df['click_onAppBefore_byDayByIp'])/(train_df['click_byDayByIp'])\n",
    "train_df['ratio_click_onAppAfter_byDayByIp'] = (train_df['click_onAppAfter_byDayByIp'])/(train_df['click_byDayByIp'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trouver qlqchose de mieux que click interval dist\n",
    "#from ggplot import *\n",
    "\n",
    "train_df['click_interval_log'] = np.log(train_df['click_interval']+1)\n",
    "#train_df['click_interval_dist_log'] = np.log(train_df['click_interval_dist']+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_df['ClickOnThisAppBefore_byDay'] = train_df['click_onAppBefore_byDayByIp']>0\n",
    "# print (train_df[['ClickOnThisAppBefore_byDay', 'is_attributed']].groupby(['ClickOnThisAppBefore_byDay'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['click_byDayByIp_log'] = np.log(train_df['click_byDayByIp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count the number of app_byChannel\n",
    "channel_uniqueApp = train_df.groupby(['ip'])['app'].nunique().reset_index()\n",
    "channel_uniqueApp.columns = ['ip','app_byIp']\n",
    "train_df = pd.merge(train_df, channel_uniqueApp, on=['ip'], how='left', sort=False)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count the number of app_byChannel\n",
    "channel_uniqueApp = train_df.groupby(['channel'])['app'].nunique().reset_index()\n",
    "channel_uniqueApp.columns = ['channel','app_byChannel']\n",
    "train_df = pd.merge(train_df, channel_uniqueApp, on=['channel'], how='left', sort=False)\n",
    "train_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count the number of click by channel\n",
    "channel_count = train_df.groupby(['channel'])['app'].count().reset_index()\n",
    "channel_count.columns = ['channel','click_byChannel']\n",
    "train_df = pd.merge(train_df, channel_count, on=['channel'], how='left', sort=False)\n",
    "train_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count the number of channel by ip\n",
    "channel_by_ip = train_df.groupby(['ip'])['channel'].nunique().reset_index()\n",
    "channel_by_ip.columns = ['ip','channel_byIP']\n",
    "train_df = pd.merge(train_df, channel_by_ip, on=['ip'], how='left', sort=False)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['click_byIp_log'] = np.log(train_df['click_byIp'])\n",
    "train_df['channel_byIP_log'] = np.log(train_df['channel_byIP'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ratio for channel\n",
    "train_df['ratio_byChannel'] = (train_df['click_byChannel']/train_df['app_byChannel'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.to_csv(path+\"trainAll_newFeatures.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
